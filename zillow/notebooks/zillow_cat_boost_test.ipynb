{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Properties ...\n",
      "Loading Train ...\n",
      "Loading Sample ...\n",
      "Merge Train with Properties ...\n",
      "Tax Features 2017  ...\n",
      "Concat Train 2016 & 2017 ...\n",
      "Remove missing data fields ...\n",
      "We exclude: 15\n",
      "Remove features with one unique value !!\n",
      "We exclude: 9\n",
      "Define training features !!\n",
      "We use these for training: 42\n",
      "Define categorial features !!\n",
      "Cat features are: ['transaction_year', 'transaction_month', 'transaction_day', 'transaction_quarter', 'airconditioningtypeid', 'buildingqualitytypeid', 'fips', 'heatingorsystemtypeid', 'propertycountylandusecode', 'propertylandusetypeid', 'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip', 'yearbuilt', 'assessmentyear']\n",
      "Replacing NaN values by -999 !!\n",
      "Training time !!\n",
      "((167888, 42), (167888,))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [47:13<00:00, 566.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for: 201612 ... \n",
      "Predicting for: 201610 ... \n",
      "Predicting for: 201611 ... \n",
      "Predicting for: 201712 ... \n",
      "Predicting for: 201711 ... \n",
      "Predicting for: 201710 ... \n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from catboost import CatBoostRegressor\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import datetime as dt\n",
    "\n",
    "print('Loading Properties ...')\n",
    "properties2016 = pd.read_csv('/Users/fangjie/Downloads/properties_2016.csv', low_memory = False)\n",
    "properties2017 = pd.read_csv('/Users/fangjie/Downloads/properties_2017.csv', low_memory = False)\n",
    "\n",
    "print('Loading Train ...')\n",
    "train2016 = pd.read_csv('/Users/fangjie/Downloads/train_2016_v2.csv', parse_dates=['transactiondate'], low_memory=False)\n",
    "train2017 = pd.read_csv('/Users/fangjie/Downloads/train_2017.csv', parse_dates=['transactiondate'], low_memory=False)\n",
    "\n",
    "def add_date_features(df):\n",
    "    df[\"transaction_year\"] = df[\"transactiondate\"].dt.year\n",
    "    df[\"transaction_month\"] = (df[\"transactiondate\"].dt.year - 2016)*12 + df[\"transactiondate\"].dt.month\n",
    "    df[\"transaction_day\"] = df[\"transactiondate\"].dt.day\n",
    "    df[\"transaction_quarter\"] = (df[\"transactiondate\"].dt.year - 2016)*4 +df[\"transactiondate\"].dt.quarter\n",
    "    df.drop([\"transactiondate\"], inplace=True, axis=1)\n",
    "    return df\n",
    "\n",
    "train2016 = add_date_features(train2016)\n",
    "train2017 = add_date_features(train2017)\n",
    "\n",
    "print('Loading Sample ...')\n",
    "sample_submission = pd.read_csv('/Users/fangjie/Downloads//sample_submission.csv', low_memory = False)\n",
    "\n",
    "print('Merge Train with Properties ...')\n",
    "train2016 = pd.merge(train2016, properties2016, how = 'left', on = 'parcelid')\n",
    "train2017 = pd.merge(train2017, properties2017, how = 'left', on = 'parcelid')\n",
    "\n",
    "print('Tax Features 2017  ...')\n",
    "train2017.iloc[:, train2017.columns.str.startswith('tax')] = np.nan\n",
    "\n",
    "print('Concat Train 2016 & 2017 ...')\n",
    "train_df = pd.concat([train2016, train2017], axis = 0)\n",
    "test_df = pd.merge(sample_submission[['ParcelId']], properties2016.rename(columns = {'parcelid': 'ParcelId'}), how = 'left', on = 'ParcelId')\n",
    "\n",
    "del properties2016, properties2017, train2016, train2017\n",
    "gc.collect();\n",
    "\n",
    "print('Remove missing data fields ...')\n",
    "\n",
    "missing_perc_thresh = 0.98\n",
    "exclude_missing = []\n",
    "num_rows = train_df.shape[0]\n",
    "for c in train_df.columns:\n",
    "    num_missing = train_df[c].isnull().sum()\n",
    "    if num_missing == 0:\n",
    "        continue\n",
    "    missing_frac = num_missing / float(num_rows)\n",
    "    if missing_frac > missing_perc_thresh:\n",
    "        exclude_missing.append(c)\n",
    "print(\"We exclude: %s\" % len(exclude_missing))\n",
    "\n",
    "del num_rows, missing_perc_thresh\n",
    "gc.collect();\n",
    "\n",
    "print (\"Remove features with one unique value !!\")\n",
    "exclude_unique = []\n",
    "for c in train_df.columns:\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if train_df[c].isnull().sum() != 0:\n",
    "        num_uniques -= 1\n",
    "    if num_uniques == 1:\n",
    "        exclude_unique.append(c)\n",
    "print(\"We exclude: %s\" % len(exclude_unique))\n",
    "\n",
    "print (\"Define training features !!\")\n",
    "exclude_other = ['parcelid', 'logerror','propertyzoningdesc']\n",
    "train_features = []\n",
    "for c in train_df.columns:\n",
    "    if c not in exclude_missing \\\n",
    "       and c not in exclude_other and c not in exclude_unique:\n",
    "        train_features.append(c)\n",
    "print(\"We use these for training: %s\" % len(train_features))\n",
    "\n",
    "print (\"Define categorial features !!\")\n",
    "cat_feature_inds = []\n",
    "cat_unique_thresh = 1000\n",
    "for i, c in enumerate(train_features):\n",
    "    num_uniques = len(train_df[c].unique())\n",
    "    if num_uniques < cat_unique_thresh \\\n",
    "       and not 'sqft' in c \\\n",
    "       and not 'cnt' in c \\\n",
    "       and not 'nbr' in c \\\n",
    "       and not 'number' in c:\n",
    "        cat_feature_inds.append(i)\n",
    "        \n",
    "print(\"Cat features are: %s\" % [train_features[ind] for ind in cat_feature_inds])\n",
    "\n",
    "print (\"Replacing NaN values by -999 !!\")\n",
    "train_df.fillna(-999, inplace=True)\n",
    "test_df.fillna(-999, inplace=True)\n",
    "\n",
    "print (\"Training time !!\")\n",
    "X_train = train_df[train_features]\n",
    "y_train = train_df.logerror\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "test_df['transactiondate'] = pd.Timestamp('2016-12-01') \n",
    "test_df = add_date_features(test_df)\n",
    "X_test = test_df[train_features]\n",
    "print(X_test.shape)\n",
    "\n",
    "num_ensembles = 5\n",
    "y_pred = 0.0\n",
    "for i in tqdm(range(num_ensembles)):\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=632, learning_rate=0.0301,\n",
    "        depth=6, l2_leaf_reg=3,\n",
    "        loss_function='MAE',\n",
    "        eval_metric='MAE',\n",
    "        random_seed=i)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        cat_features=cat_feature_inds)\n",
    "    y_pred += model.predict(X_test)\n",
    "y_pred /= num_ensembles\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ParcelId': test_df['ParcelId'],\n",
    "})\n",
    "test_dates = {\n",
    "    '201610': pd.Timestamp('2016-09-30'),\n",
    "    '201611': pd.Timestamp('2016-10-31'),\n",
    "    '201612': pd.Timestamp('2016-11-30'),\n",
    "    '201710': pd.Timestamp('2017-09-30'),\n",
    "    '201711': pd.Timestamp('2017-10-31'),\n",
    "    '201712': pd.Timestamp('2017-11-30')\n",
    "}\n",
    "for label, test_date in test_dates.items():\n",
    "    print(\"Predicting for: %s ... \" % (label))\n",
    "    submission[label] = y_pred\n",
    "    \n",
    "submission.to_csv('/Users/fangjie/Downloads/catsubmission.csv', float_format='%.6f',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
